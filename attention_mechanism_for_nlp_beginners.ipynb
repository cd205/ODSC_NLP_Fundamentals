{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "attention-mechanism-for-nlp-beginners.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sgujdWmNzdt"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "We will now discuss about Transformers'**Attention Mechanism**, used as a basic model for GPT and BERT. It's important to understand state-of-the-art language models. We will go though an excercise French-English translation of a pioece of text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9NtrT_ANzdx"
      },
      "source": [
        "<a class=\"anchor\" id=\"0.1\"></a>\n",
        "#  üí• Table of Contents\n",
        "i.  [How do I translate the sentence by machine? : Appearance of Attention Mechanism](#1)\n",
        "\n",
        "ii.  [What is Attention's idea?](#2)\n",
        "\n",
        "iii.  [Attention's process](#3)\n",
        "\n",
        "   - [Find the attention score](#3.1)\n",
        "   - [Attention distribution is obtained through the softmax function](#3.2)\n",
        "   - [Attention Value is obtained by weighting the attention weights and the hidden state of each encoder](#3.3)\n",
        "   - [Concatenate : connects the attention value with the hidden state at time t of the decoder](#3.4)\n",
        "   - [Calculating  **ùë†ÃÉ** the input to output layer operation](#3.5)\n",
        "   - [Use **ùë†ÃÉ** as the input for the output layer](#3.6)\n",
        "\n",
        "\n",
        "iv. [seq2seq with attention vs traditional seq2seq](#4)\n",
        "\n",
        "\n",
        "v. [Different types of attention](#5)\n",
        "\n",
        "\n",
        "vi. [Additional Concepts : Teacher Forcing](#6)\n",
        "\n",
        "\n",
        "vii. [French-English Machine Translation Tutorial: Using Pytorch](#7)\n",
        "\n",
        "\n",
        "viii. [conclusion](#17)\n",
        "\n",
        "\n",
        "ix. [References](#18) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtMSvxG2Nzdy"
      },
      "source": [
        "# 1. How do I translate the sentence by machine? : Appearance of Attention Mechanism <a class=\"anchor\" id=\"1\"></a>\n",
        "\n",
        "The seq2seq model compresses the input sequence into one fixed-size vector representation, called the context vector, through which the decoder produces the output sequence. Through this, each word can be translated.\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FprTT1%2FbtqChF6Z2BM%2FyKmITHEga1J0ZYFWEMr8Y0%2Fimg.png\"/ width=\"500\" height=\"500\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$\n",
        "\n",
        "Let's take a look at the seq2seq model using RNN. \"I\" comes first, \"love\" comes next, and \"you\" comes next. Consequently, the final RNN cell states \"I love you\". This vector is called the **context vector**.\n",
        "\n",
        "**Encoder** eventually creates a context vector by receiving each word sequentially. **Decoder** starts machine translation from this context vector. From start to end, the words in it are translated immediately.\n",
        "\n",
        "However, there are two main problems with seq2seq models based on these RNNs.\n",
        "\n",
        "   1. **trying to compress all the information into one fixed-size vector results in information loss.** \n",
        "   2. **there exists the Vanishing Gradient problem, which is a chronic problem of RNN.**\n",
        "\n",
        "In other words, in the field of machine translation, if the input sentence is long, the translation quality is poor. Attention helps in this case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCCoBLvkNzdz"
      },
      "source": [
        "# 2. What is Attention's idea? <a class=\"anchor\" id=\"2\"></a>\n",
        "\n",
        "The basic idea of Attention is that at every time step that the decoder predicts output words, it references the entire input sentence from the encoder. However, instead of referring to all the input sentences at the same rate, you will focus more on the parts of the input words that are related to the words you need to predict at that point.\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FYzQNQ%2FbtqCe5rLdtM%2FKuUvWxOTdTLlOte7lVm4i1%2Fimg.png\"/ width=\"500\" height=\"500\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$\n",
        "\n",
        "In other words, each state from the encoder, each RNN cell, is utilized. We can summarize the advantages of Attention in two ways here.\n",
        "\n",
        "   1. **It is not a fixed size context vector. The problem that comes from one fixed-size context vector is to refresh the context vector for each state.** \n",
        "   2. **Of all the states in Encoder, we can design a mechanism that can only focus on the words we need to focus on.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5im0QgCNzd1"
      },
      "source": [
        "# 3. Attention's process <a class=\"anchor\" id=\"3\"></a>\n",
        "\n",
        "OK! If you have a rough idea of Attention, let's look at the Attention process. There are many different types of Attention, and let's understand it through Dot-Product Attention, which is the most informally easy to understand formula. Among the attractions used in seq2seq, the difference between dot-product attention and other attention is largely the difference in intermediate formulas, and the mechanism itself is almost similar. I'll explain it again after various Attentions.\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://wikidocs.net/images/page/22893/dotproductattention1_final.PNG\"/ width=\"500\" height=\"500\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$\n",
        "\n",
        "The third LSTM cell in the decoder shows the use of an attention mechanism when predicting output words. Suppose that the first and second LSTM cells in the decoder have already gone through the attention mechanism to predict je and suis. Before explaining the attention mechanism in detail, let's first get a sense of the overall picture above. The third LSTM cell in the decoder wants to refer to the information of all the input words in the encoder once again to predict the output words. The description of the intermediate process is currently omitted, and what is noteworthy here is the softmax function of the encoder.\n",
        "\n",
        "The resulting value of the softmax function is a numerical value of how helpful each of the words I, am, a, and student is when predicting the output word. The figure above shows the magnitude of the resultant value of the softmax function in the size of a red rectangle. The larger the rectangle, the larger the helpful it is. When each input word is quantified and measured to help you predict the decoder, it is sent to the decoder with one piece of information. In the figure above, the green triangle corresponds to this. As a result, the decoder is more likely to predict output words more accurately. Now that we have a holistic sense of the attention mechanism.\n",
        "\n",
        "Let's look at the following as an easier example.\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FG1u0d%2FbtqCl9U65jT%2F3w2vCPrTIRU0a14bWNooo1%2Fimg.png\"/ width=\"400\" height=\"400\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$\n",
        "\n",
        "First of all, there is a **Fully connected network (FC)**. We utilize $h_1$, $h_2$, ... $h_N$ (the states of all RNN cells from the encoder). And I put in the final H3. Because there is no value from the decoder under the current circumstances, we simply put in the state value that existed before. Output values from the fully connected network are $s_1$, $s_2$, and $s_3$, the scores on the RNN cell in each encoder.\n",
        "\n",
        "Now that we have a holistic sense of the attention mechanism, let's take a closer look at the attention mechanism.\n",
        "\n",
        "\n",
        "### 1. Find the attention score <a class=\"anchor\" id=\"3.1\"></a>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://wikidocs.net/images/page/22893/dotproductattention2_final.PNG\"/ width=\"500\" height=\"500\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$\n",
        "\n",
        "If the time step of the encoder is 1, 2, and N respectively, then the hidden state of time step of the encoder is  $h_1$, $h_2$, ... $h_N$ respectively. Let the decoder's hidden state at the time step t of the decoder be S. We also assume here that the hidden state of the encoder and the hidden state of the decoder are the same dimensions. For the above figure, the encoder's hidden state and the decoder's hidden state are the same dimension 4.\n",
        "\n",
        "The attention mechanism requires a new value called Attention Value for output word prediction. Let's define the attention value to predict the t-th word as $a_t$.\n",
        "\n",
        "An attention score is a score value that determines how similar each of the hidden states of the encoder is to the hidden state $s_t$ of the decoder at this point in time to predict the word at point t of the current decoder.\n",
        "\n",
        "Dot-Product Attention will transpose $s_t$, perform each hidden state and dot product to obtain the value of this score. That is, all attention score values are scalar. For example, the method of calculating the attention score of $s_t$ and the ith hidden state of the encoder is shown below.\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://wikidocs.net/images/page/22893/i%EB%B2%88%EC%A7%B8%EC%96%B4%ED%85%90%EC%85%98%EC%8A%A4%EC%BD%94%EC%96%B4_final.PNG\"/ width=\"300\" height=\"300\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$\n",
        "\n",
        "Define the attention score function as follows :\n",
        "\n",
        "$$\n",
        "\\operatorname{score}(s_i, h_i) = s_{t}^Th_{i}\n",
        "$$\n",
        "\n",
        "Let's define the collection value of all hidden attention scores of $s_t$, and encoder as $e^t$. The formula for $e^t$ is as follows.\n",
        "\n",
        "$$\n",
        "\\operatorname{e^t} = [s_{t}^Th_{1}, \\operatorname{...}, s_{t}^Th_{N}]\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### 2. Attention distribution is obtained through the softmax function <a class=\"anchor\" id=\"3.2\"></a>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://wikidocs.net/images/page/22893/dotproductattention3_final.PNG\"/ width=\"500\" height=\"500\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$\n",
        "\n",
        "By applying the softmax function to $e^t$, you obtain a probability distribution that adds all values to 1. This is known as the Attention Distribution, and each value is known as the Attention Weight. In addition, the size of the attention weights in the hidden state of each encoder was visualized through the size of the rectangle. That is, the greater the attention weight, the larger the rectangle.\n",
        "\n",
        "Let me look at an easier example.\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdnaBKf%2FbtqCsIuHK8B%2FGKHuV1AgOI9e8bKt90kFp0%2Fimg.png\"/ width=\"400\" height=\"400\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$\n",
        "\n",
        "The above figure shows the probability value of taking the softmax value of \"I love you\". 90% for \"I\", 0% for \"love\", and 10% for \"you\". This is called Attention weight and these values indicate how much we will focus.\n",
        "\n",
        "When the attention distribution, which is a collection of attention weights at point t of the decoder, is called $a^t$, defining $a^t$ as an expression :\n",
        "\n",
        "$$\n",
        "a_t = \\text{softmax}(e^t)\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 3. Attention Value is obtained by weighting the attention weights and the hidden state of each encoder <a class=\"anchor\" id=\"3.3\"></a>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://wikidocs.net/images/page/22893/dotproductattention4_final.PNG\"/ width=\"500\" height=\"500\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$\n",
        "\n",
        "Now it's time to combine the information we've prepared so far into one. To obtain the final result of the attention, we multiply the hidden state of each encoder and the attention weights, and finally add them all. In summary, you might say weighed Sum. Below is the final result of the attention, i.e., an expression for the attention value $a_t$, the output of the attention function.\n",
        "\n",
        "$$\n",
        "a_t = \\sum_{i=1}^{N} a_{i}^{t}h_i\n",
        "$$\n",
        "\n",
        "The attention value $a_t$ is also called the **context vector** because it often contains the context of the encoder.\n",
        "\n",
        "Let me give you an easy example.\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbCGz9v%2FbtqCqNjebAu%2F77pnvKbjaNeIrPj3yM0MQ0%2Fimg.png\"/ width=\"400\" height=\"400\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$\n",
        "\n",
        "cv1 stands for context vector1. **cv1 = $h_1$ * 0.9 + $h_2$ * 0 + $h_3$ * 0.1.** In other words, the first context vector is I for 90% and you for 10%.\n",
        "\n",
        "\n",
        "\n",
        "### 4. Concatenate : connects the attention value with the hidden state at time t of the decoder <a class=\"anchor\" id=\"3.4\"></a>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://wikidocs.net/images/page/22893/dotproductattention5_final_final.PNG\"/ width=\"500\" height=\"500\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$\n",
        "\n",
        "You have now obtained the final value of the attention function, the attention value $a_t$. Earlier, we introduced the following expression as an expression to determine the hidden state at point t with the attention mechanism: In fact, when the attention value is obtained, the attention mechanism concatenates $a_t$ with $s_t$ to form a vector. Let's define this as $v_t$. By using this $v_t$ as the input for the $\\hat{y}$ prediction operation, we can leverage the information from the encoder to better predict $\\hat{y}$. **This is at the heart of the attention mechanism.**\n",
        "\n",
        "Let's take another easy example.\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FCpNnB%2FbtqCrPOozvr%2FEXUeB68QIoA2ucSkvW5K0K%2Fimg.png\"/ width=\"400\" height=\"400\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$\n",
        "\n",
        "In the picture above, the output 'Nan' is shown. What will the second word come from? The second word is that the current state value in the decoder goes into FC. **What we need to note is that $h_1$, $h_2$, and $h_3$ are always used.**\n",
        "\n",
        "\n",
        "\n",
        "### 5. Calculating ùë†ÃÉ the input to output layer operation <a class=\"anchor\" id=\"3.5\"></a>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://wikidocs.net/images/page/22893/st.PNG\"/ width=\"500\" height=\"500\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$\n",
        "\n",
        "In the paper, we added another neural network operation before sending $v_t$ directly to the output layer. Multiply with the weight matrix and pass through the hyperbolic tangent function to obtain $\\hat{s}_t$, a new vector for output layer operations. In seq2seq, which does not use the attention mechanism, the input of the output layer is $s_t$ hidden at point t, while in the attention mechanism, the input of the output layer is $\\hat{s}_t$.\n",
        "\n",
        "Expressing this as an expression: In expressions, $W_c$ is the learnable weight matrix, and $b_c$ is the bias. Deflection is omitted in the figure.\n",
        "\n",
        "$$\n",
        "\\tilde{s}_{t} = \\tanh(\\mathbf{W_{c}}[{a}_t;{s}_t] + b_{c})\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### 6. Use ùë†ÃÉ as the input for the output layer <a class=\"anchor\" id=\"3.6\"></a>\n",
        "\n",
        "Use $\\hat{s}_t$ as the input to the output layer to obtain the prediction vector.\n",
        "\n",
        "$$\n",
        "\\widehat{y}_t = \\text{Softmax}\\left( W_y\\tilde{s}_t + b_y \\right)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xCHzqaVNzd4"
      },
      "source": [
        "# 4. seq2seq with attention vs. traditional seq2seq <a class=\"anchor\" id=\"4\"></a>\n",
        "\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSBp7-TJBXCkCm91-SRfwloIMXgm_O9s9ZyYw&usqp=CAU\"/ width=\"500\" height=\"500\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$\n",
        "\n",
        "We show remarkable performance on the final result graph. In the graph, 'RNNenc' stands for conventional RNN Encoder-Decoder without Attention applied, and 'RNNsearch' stands for RNN Encoder-Decoder with Attention applied. The numbers \"30\" and \"50\" mean that the network has been trained in one sentence, each consisting of words below that number. Finally, the horizontal axis of the graph represents the length of the test sentence and the vertical axis represents the BLEUS score, an indicator used to represent translation performance.\n",
        "\n",
        "First of all, comparing the existing RNNenc-30 and RNNsearch-30, we can see that significant improvements in translation performance have been made even if it is not a long sentence. This records higher performance than RNNenc-50 does. Secondly, comparing RNNenc-50 and RNNsearch-50 shows that, again, translation performance has been improved, and remarkably, RNNsearch-50 does not have a degradation problem with translation performance even with longer sentence lengths.\n",
        "\n",
        "[Back to Table of Contents](#0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBW-NXuJNzd6"
      },
      "source": [
        "# French-English Machine Translation Tutorial - Using Pytorch <a class=\"anchor\" id=\"7\"></a>\n",
        "\n",
        "We implement a simple machine translation project to help NLP beginners understand the attention mechanism. Many examples using Tensorflow exist, but we recently wrote them with a popular framework, Pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUPadsYSNzd7"
      },
      "source": [
        "#### 1. Loading Libraries <a class=\"fra-eng\" id=\"8\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:39.256362Z",
          "iopub.status.busy": "2021-06-03T12:59:39.256037Z",
          "iopub.status.idle": "2021-06-03T12:59:39.264077Z",
          "shell.execute_reply": "2021-06-03T12:59:39.263138Z",
          "shell.execute_reply.started": "2021-06-03T12:59:39.256329Z"
        },
        "id": "S86yKkUANzd8"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "import urllib3\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QnP_m2DNzd9"
      },
      "source": [
        "#### 2. Download and load data files <a class=\"fra-eng\" id=\"9\"></a>\n",
        "\n",
        "Before writing the code, download the data provided by https://www.manythings.org/anki/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:39.732491Z",
          "iopub.status.busy": "2021-06-03T12:59:39.732174Z",
          "iopub.status.idle": "2021-06-03T12:59:40.459303Z",
          "shell.execute_reply": "2021-06-03T12:59:40.458247Z",
          "shell.execute_reply.started": "2021-06-03T12:59:39.732461Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "E17TPpbvNzd9",
        "outputId": "099dacda-a83a-459e-fe12-d262ab3e1d12"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "url = 'http://www.manythings.org/anki/fra-eng.zip'\n",
        "file_name = 'fra-eng.zip'\n",
        "root_path = '/content/drive/MyDrive/Colab Notebooks/DL/input/fra-eng/'\n",
        "file_path = os.path.join(root_path, file_name)\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# with http.request('GET', url, preload_content = False) as r, open(zipfilename, 'wb') as out_file:\n",
        "#   shutil.copyfileobj(r, out_file)\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(file_path)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-65c37722dd69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/DL/input/fra-eng/fra-eng.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:40.463132Z",
          "iopub.status.busy": "2021-06-03T12:59:40.461820Z",
          "iopub.status.idle": "2021-06-03T12:59:41.140090Z",
          "shell.execute_reply": "2021-06-03T12:59:41.139062Z",
          "shell.execute_reply.started": "2021-06-03T12:59:40.463091Z"
        },
        "id": "yX7dTnJaNzd9",
        "outputId": "88252063-e873-41b8-cd18-dfc422022dba"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "__notebook_source__.ipynb  _about.txt  fra-eng.zip  fra.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1y1cSD-Nzd-"
      },
      "source": [
        "You can see that the file has been downloaded normally. If it's not downloaded properly, check your internet connection !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNpNtRvPNzd-"
      },
      "source": [
        "#### 3. Preparation for data preprocessing <a class=\"fra-eng\" id=\"10\"></a>\n",
        "\n",
        "Unlike dozens of characters in a single language, the encoding vector is very large because there are so many words in the translation. Therefore, we will refine the data to use only thousands of words per language using the method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:41.142303Z",
          "iopub.status.busy": "2021-06-03T12:59:41.141953Z",
          "iopub.status.idle": "2021-06-03T12:59:41.150133Z",
          "shell.execute_reply": "2021-06-03T12:59:41.149117Z",
          "shell.execute_reply.started": "2021-06-03T12:59:41.142266Z"
        },
        "id": "LqLjToD4Nzd_"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: 'SOS', 1: 'EOS'}\n",
        "        self.n_words = 2\n",
        "    \n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "    \n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lptweAaONzd_"
      },
      "source": [
        "Create a class to store downloaded data as word->index, index->words and replace rare words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:41.306654Z",
          "iopub.status.busy": "2021-06-03T12:59:41.306300Z",
          "iopub.status.idle": "2021-06-03T12:59:41.312014Z",
          "shell.execute_reply": "2021-06-03T12:59:41.311136Z",
          "shell.execute_reply.started": "2021-06-03T12:59:41.306618Z"
        },
        "id": "htUO-ayWNzd_"
      },
      "source": [
        "# Convert Unicode strings to plain ASCII\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Remove lowercase letters, trimming, and non-character characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rcnVezINzd_"
      },
      "source": [
        "The file is all Unicode, which converts Unicode characters to ASCII for simplicity, makes all characters lowercase, and erases most punctuation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:41.825675Z",
          "iopub.status.busy": "2021-06-03T12:59:41.824963Z",
          "iopub.status.idle": "2021-06-03T12:59:41.835415Z",
          "shell.execute_reply": "2021-06-03T12:59:41.834434Z",
          "shell.execute_reply.started": "2021-06-03T12:59:41.825606Z"
        },
        "id": "tvuSXkSsNzeA"
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and separate it into lines\n",
        "    lines = open('./%s.txt' % (lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "    \n",
        "    # Separate all lines in pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')][:2] for l in lines]\n",
        "    \n",
        "    # Flip pairs, create Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVrQO4SzNzeA"
      },
      "source": [
        "To read the data file we will split the file into lines, and then split lines into pairs. The files are all English ‚Üí Other Language, so if we want to translate from Other Language ‚Üí English I added the reverse flag to reverse the pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:42.315262Z",
          "iopub.status.busy": "2021-06-03T12:59:42.314941Z",
          "iopub.status.idle": "2021-06-03T12:59:42.320840Z",
          "shell.execute_reply": "2021-06-03T12:59:42.320006Z",
          "shell.execute_reply.started": "2021-06-03T12:59:42.315230Z"
        },
        "id": "9twxwaeONzeA"
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBSnTjS5NzeA"
      },
      "source": [
        "Since there are a lot of example sentences and we want to train something quickly, we‚Äôll trim the data set to only relatively short and simple sentences. Here the maximum length is 10 words (that includes ending punctuation) and we‚Äôre filtering to sentences that translate to the form ‚ÄúI am‚Äù or ‚ÄúHe is‚Äù etc. (accounting for apostrophes replaced earlier)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLRtch_1NzeB"
      },
      "source": [
        "The full process for preparing the data is:\n",
        "\n",
        "* Read text file and split into lines, split lines into pairs\n",
        "* Normalize text, filter by length and content\n",
        "* Make word lists from sentences in pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:43.083881Z",
          "iopub.status.busy": "2021-06-03T12:59:43.083476Z",
          "iopub.status.idle": "2021-06-03T12:59:59.382432Z",
          "shell.execute_reply": "2021-06-03T12:59:59.381597Z",
          "shell.execute_reply.started": "2021-06-03T12:59:43.083846Z"
        },
        "id": "UkAQFonsNzeB",
        "outputId": "4a49a4d0-ac25-4749-b8e6-94f64db2af23"
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 185583 sentence pairs\n",
            "Trimmed to 13732 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4972\n",
            "eng 3179\n",
            "['je ne ressens pas particulierement la faim .', 'i m not feeling particularly hungry .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "485OzJzjNzeB"
      },
      "source": [
        "[Back to Table of Contents](#0.1)\n",
        "\n",
        "[Back to fra-eng Table of Contents](#0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35jcOw3vNzeB"
      },
      "source": [
        "#### 4. Modeling : Seq2Seq Model and Attention Decoder <a class=\"fra-eng\" id=\"11\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq0a_pAfNzeB"
      },
      "source": [
        "* The Encoder\n",
        "\n",
        "The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word.\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://pytorch.org/tutorials/_images/encoder-network.png\"/ width=\"300\" height=\"300\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:59.384281Z",
          "iopub.status.busy": "2021-06-03T12:59:59.383933Z",
          "iopub.status.idle": "2021-06-03T12:59:59.391829Z",
          "shell.execute_reply": "2021-06-03T12:59:59.390920Z",
          "shell.execute_reply.started": "2021-06-03T12:59:59.384245Z"
        },
        "id": "HCm8-K6ZNzeB"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9eycT2ENzeC"
      },
      "source": [
        "* The Decoder\n",
        "\n",
        "The decoder is another RNN that takes the encoder output vector(s) and outputs a sequence of words to create the translation.\n",
        "\n",
        "In the simplest seq2seq decoder we use only last output of the encoder. This last output is sometimes called the context vector as it encodes context from the entire sequence. This context vector is used as the initial hidden state of the decoder.\n",
        "\n",
        "At every step of decoding, the decoder is given an input token and hidden state. The initial input token is the start-of-string <SOS> token, and the first hidden state is the context vector (the encoder‚Äôs last hidden state).\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://pytorch.org/tutorials/_images/decoder-network.png\"/ width=\"300\" height=\"300\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:59.394153Z",
          "iopub.status.busy": "2021-06-03T12:59:59.393817Z",
          "iopub.status.idle": "2021-06-03T12:59:59.404354Z",
          "shell.execute_reply": "2021-06-03T12:59:59.403520Z",
          "shell.execute_reply.started": "2021-06-03T12:59:59.394117Z"
        },
        "id": "v7fChZWSNzeC"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkuqG8aSNzeC"
      },
      "source": [
        "* Attention Decoder\n",
        "\n",
        "Attention allows the decoder network to ‚Äúfocus‚Äù on a different part of the encoder‚Äôs outputs for every step of the decoder‚Äôs own outputs. First we calculate a set of attention weights. These will be multiplied by the encoder output vectors to create a weighted combination. The result (called attn_applied in the code) should contain information about that specific part of the input sequence, and thus help the decoder choose the right output words.\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://i.imgur.com/1152PYf.png\"/ width=\"300\" height=\"300\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$\n",
        "\n",
        "Calculating the attention weights is done with another feed-forward layer attn, using the decoder‚Äôs input and hidden state as inputs. Because there are sentences of all sizes in the training data, to actually create and train this layer we have to choose a maximum sentence length (input length, for encoder outputs) that it can apply to. Sentences of the maximum length will use all the attention weights, while shorter sentences will only use the first few.\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$ \n",
        "<center><img src=\"https://pytorch.org/tutorials/_images/attention-decoder-network.png\"/ width=\"300\" height=\"300\" ></center>\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;\\;$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:59.406349Z",
          "iopub.status.busy": "2021-06-03T12:59:59.405932Z",
          "iopub.status.idle": "2021-06-03T12:59:59.417869Z",
          "shell.execute_reply": "2021-06-03T12:59:59.416745Z",
          "shell.execute_reply.started": "2021-06-03T12:59:59.406314Z"
        },
        "id": "ozERfXslNzeC"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbii5Ie6NzeC"
      },
      "source": [
        "[Back to Table of Contents](#0.1)\n",
        "\n",
        "[Back to fra-eng Table of Contents](#0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuEtnAjcNzeD"
      },
      "source": [
        "#### 5. Train Data Preparation <a class=\"fra-eng\" id=\"12\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:59.419742Z",
          "iopub.status.busy": "2021-06-03T12:59:59.419301Z",
          "iopub.status.idle": "2021-06-03T12:59:59.430549Z",
          "shell.execute_reply": "2021-06-03T12:59:59.429857Z",
          "shell.execute_reply.started": "2021-06-03T12:59:59.419710Z"
        },
        "id": "YjbdCOR6NzeD"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvxhUhFUNzeD"
      },
      "source": [
        "To train, for each pair we will need an input tensor (indexes of the words in the input sentence) and target tensor (indexes of the words in the target sentence). While creating these vectors we will append the EOS token to both sequences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNrkuQZwNzeD"
      },
      "source": [
        "#### 6. Train Data Preparation <a class=\"fra-eng\" id=\"13\"></a>\n",
        "\n",
        "To train we run the input sentence through the encoder, and keep track of every output and the latest hidden state. Then the decoder is given the <SOS> token as its first input, and the last hidden state of the encoder as its first hidden state.\n",
        "\n",
        "‚ÄúTeacher forcing‚Äù is the concept of using the real target outputs as each next input, instead of using the decoder‚Äôs guess as the next input. Using teacher forcing causes it to converge faster but when the trained network is exploited, it may exhibit instability.\n",
        "\n",
        "You can observe outputs of teacher-forced networks that read with coherent grammar but wander far from the correct translation - intuitively it has learned to represent the output grammar and can ‚Äúpick up‚Äù the meaning once the teacher tells it the first few words, but it has not properly learned how to create the sentence from the translation in the first place.\n",
        "\n",
        "Because of the freedom PyTorch‚Äôs autograd gives us, we can randomly choose to use teacher forcing or not with a simple if statement. Turn teacher_forcing_ratio up to use more of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:59.433322Z",
          "iopub.status.busy": "2021-06-03T12:59:59.433024Z",
          "iopub.status.idle": "2021-06-03T12:59:59.443869Z",
          "shell.execute_reply": "2021-06-03T12:59:59.442946Z",
          "shell.execute_reply.started": "2021-06-03T12:59:59.433298Z"
        },
        "id": "9fZsBATRNzeD"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:59.445539Z",
          "iopub.status.busy": "2021-06-03T12:59:59.444982Z",
          "iopub.status.idle": "2021-06-03T12:59:59.456719Z",
          "shell.execute_reply": "2021-06-03T12:59:59.455996Z",
          "shell.execute_reply.started": "2021-06-03T12:59:59.445504Z"
        },
        "id": "zgATMgJZNzeD"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYrXVRRUNzeE"
      },
      "source": [
        "This is a helper function to print time elapsed and estimated time remaining given the current time and progress %."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jMV47ufNzeE"
      },
      "source": [
        "The whole training process looks like this:\n",
        "\n",
        "* Start a timer\n",
        "* Initialize optimizers and criterion\n",
        "* Create set of training pairs\n",
        "* Start empty losses array for plotting\n",
        "\n",
        "Then we call train many times and occasionally print the progress (% of examples, time so far, estimated time) and average loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:59.459548Z",
          "iopub.status.busy": "2021-06-03T12:59:59.459167Z",
          "iopub.status.idle": "2021-06-03T12:59:59.474302Z",
          "shell.execute_reply": "2021-06-03T12:59:59.473269Z",
          "shell.execute_reply.started": "2021-06-03T12:59:59.459500Z"
        },
        "id": "o2Xx-DTJNzeE"
      },
      "source": [
        "%matplotlib inline\n",
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:59.476373Z",
          "iopub.status.busy": "2021-06-03T12:59:59.475933Z",
          "iopub.status.idle": "2021-06-03T12:59:59.486033Z",
          "shell.execute_reply": "2021-06-03T12:59:59.485224Z",
          "shell.execute_reply.started": "2021-06-03T12:59:59.476338Z"
        },
        "id": "BhqKHuWbNzeE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    \n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX1QaqTMNzeE"
      },
      "source": [
        "Plotting is done with matplotlib, using the array of loss values plot_losses saved while training.\n",
        "\n",
        "[Back to Table of Contents](#0.1)\n",
        "\n",
        "[Back to fra-eng Table of Contents](#0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ib01CgLNzeE"
      },
      "source": [
        "#### 7. Evaluation <a class=\"fra-eng\" id=\"14\"></a>\n",
        "\n",
        "\n",
        "Evaluation is mostly the same as training, but there are no targets so we simply feed the decoder‚Äôs predictions back to itself for each step. Every time it predicts a word we add it to the output string, and if it predicts the EOS token we stop there. We also store the decoder‚Äôs attention outputs for display later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:59.487688Z",
          "iopub.status.busy": "2021-06-03T12:59:59.487270Z",
          "iopub.status.idle": "2021-06-03T12:59:59.499958Z",
          "shell.execute_reply": "2021-06-03T12:59:59.499010Z",
          "shell.execute_reply.started": "2021-06-03T12:59:59.487639Z"
        },
        "id": "soApQIlINzeE"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:59.501847Z",
          "iopub.status.busy": "2021-06-03T12:59:59.501370Z",
          "iopub.status.idle": "2021-06-03T12:59:59.510639Z",
          "shell.execute_reply": "2021-06-03T12:59:59.509711Z",
          "shell.execute_reply.started": "2021-06-03T12:59:59.501808Z"
        },
        "id": "MI3UMb8cNzeF"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAOj-jRQNzeF"
      },
      "source": [
        "We can evaluate random sentences from the training set and print out the input, target, and output to make some subjective quality judgements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncJc6T5oNzeF"
      },
      "source": [
        "#### 8. Training and Evaluating <a class=\"fra-eng\" id=\"15\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T12:59:59.512425Z",
          "iopub.status.busy": "2021-06-03T12:59:59.511926Z",
          "iopub.status.idle": "2021-06-03T13:24:16.352515Z",
          "shell.execute_reply": "2021-06-03T13:24:16.351607Z",
          "shell.execute_reply.started": "2021-06-03T12:59:59.512374Z"
        },
        "id": "-1xuc9C6NzeF",
        "outputId": "41454968-1fa8-425f-d110-5929e14e0990"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1m 39s (- 23m 14s) (5000 6%) 2.8987\n",
            "3m 13s (- 21m 0s) (10000 13%) 2.3419\n",
            "4m 49s (- 19m 16s) (15000 20%) 2.0203\n",
            "6m 24s (- 17m 37s) (20000 26%) 1.7932\n",
            "8m 0s (- 16m 1s) (25000 33%) 1.6271\n",
            "9m 38s (- 14m 27s) (30000 40%) 1.4799\n",
            "11m 15s (- 12m 51s) (35000 46%) 1.3693\n",
            "12m 52s (- 11m 15s) (40000 53%) 1.2639\n",
            "14m 30s (- 9m 40s) (45000 60%) 1.1523\n",
            "16m 6s (- 8m 3s) (50000 66%) 1.0411\n",
            "17m 45s (- 6m 27s) (55000 73%) 0.9861\n",
            "19m 22s (- 4m 50s) (60000 80%) 0.8950\n",
            "21m 0s (- 3m 13s) (65000 86%) 0.8242\n",
            "22m 38s (- 1m 37s) (70000 93%) 0.7506\n",
            "24m 16s (- 0m 0s) (75000 100%) 0.7006\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezI02z5rNzeF"
      },
      "source": [
        "You can see that the leftmost loss decreases as the learning progresses. We also show fast learning time on a large number of 75,000 data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T13:24:16.354130Z",
          "iopub.status.busy": "2021-06-03T13:24:16.353814Z",
          "iopub.status.idle": "2021-06-03T13:24:16.435324Z",
          "shell.execute_reply": "2021-06-03T13:24:16.434032Z",
          "shell.execute_reply.started": "2021-06-03T13:24:16.354104Z"
        },
        "id": "WGBjcu_XNzeF",
        "outputId": "62825274-5cdf-437c-bb8e-47cc7452e0d3"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> je suis triste sans vous .\n",
            "= i m sad without you .\n",
            "< i m sad without you . <EOS>\n",
            "\n",
            "> ils sourient .\n",
            "= they re smiling .\n",
            "< they re smiling . <EOS>\n",
            "\n",
            "> je ne suis pas sourd .\n",
            "= i am not deaf .\n",
            "< i m not deaf . <EOS>\n",
            "\n",
            "> vous etes tous satisfaits .\n",
            "= you re all happy .\n",
            "< you re all happy . <EOS>\n",
            "\n",
            "> je ne suis pas fier de moi .\n",
            "= i m not proud of myself .\n",
            "< i m not proud of myself . <EOS>\n",
            "\n",
            "> je suis toujours fatigue .\n",
            "= i m always tired .\n",
            "< i m always tired . <EOS>\n",
            "\n",
            "> je suis aneanti .\n",
            "= i m devastated .\n",
            "< i m a . . <EOS>\n",
            "\n",
            "> c est ma fille .\n",
            "= she s my daughter .\n",
            "< she s my daughter . <EOS>\n",
            "\n",
            "> tu es beau .\n",
            "= you are beautiful .\n",
            "< you re beautiful . <EOS>\n",
            "\n",
            "> je vais changer tout ca .\n",
            "= i m going to change all that .\n",
            "< i m going to miss it . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3_uPH_zNzeF"
      },
      "source": [
        "[Back to Table of Contents](#0.1)\n",
        "\n",
        "[Back to fra-eng Table of Contents](#0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4fxu9FKNzeG"
      },
      "source": [
        "#### 8. Visualize the Attention Process <a class=\"fra-eng\" id=\"16\"></a>\n",
        "\n",
        "A useful property of the attention mechanism is its highly interpretable outputs. Because it is used to weight specific encoder outputs of the input sequence, we can imagine looking where the network is focused most at each time step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T13:24:16.436852Z",
          "iopub.status.busy": "2021-06-03T13:24:16.436500Z",
          "iopub.status.idle": "2021-06-03T13:24:16.657327Z",
          "shell.execute_reply": "2021-06-03T13:24:16.656459Z",
          "shell.execute_reply.started": "2021-06-03T13:24:16.436815Z"
        },
        "id": "-NvWtgQ8NzeG",
        "outputId": "d17b9cef-3e89-4ba8-b1a9-6710107c5d73"
      },
      "source": [
        "%matplotlib inline\n",
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
        "plt.matshow(attentions.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb0e1db2750>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 480x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaVioq2uNzeG"
      },
      "source": [
        "For a better viewing experience we will do the extra work of adding axes and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T13:24:16.663920Z",
          "iopub.status.busy": "2021-06-03T13:24:16.661549Z",
          "iopub.status.idle": "2021-06-03T13:24:18.134028Z",
          "shell.execute_reply": "2021-06-03T13:24:18.133110Z",
          "shell.execute_reply.started": "2021-06-03T13:24:16.663876Z"
        },
        "id": "qyoPT3s1NzeG",
        "outputId": "3d42e19d-3b0a-4b01-865f-6b77cfbee7fb"
      },
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # colorbarÎ°ú Í∑∏Î¶º ÏÑ§Ï†ï\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Ï∂ï ÏÑ§Ï†ï\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Îß§ Ìã±ÎßàÎã§ ÎùºÎ≤® Î≥¥Ïó¨Ï£ºÍ∏∞\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
        "\n",
        "evaluateAndShowAttention(\"elle est trop petit .\")\n",
        "\n",
        "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
        "\n",
        "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input = elle a cinq ans de moins que moi .\n",
            "output = she is five years younger than i am . <EOS>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input = elle est trop petit .\n",
            "output = she is too close . <EOS>\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD9CAYAAAC2l2x5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYtElEQVR4nO3de7hdVX3u8e9L5KKAoGx6UC6GnhOqUZFLRFtBUYEGi2IfrFzq7RSNtmLrUSjh6EN5AKuUUgstWCMXA1opcoTmKJ7gBaQPVknCJZBIfPKAloBUgxTjFZL9nj/m3LCy2XuvnbXmWnPumffDM5+95phjjTEWyf6tkTHHHEO2iYiI9tmm7gZERMRgJMBHRLRUAnxEREslwEdEtFQCfERESyXAR0S0VAJ8RERLJcBHRLRUAnxEREslwEd0UOF6SS+quy0R/UqAj9jcUcDLgXfX3ZCIfiXAR2zuZIrg/kZJz6i7MRH9SICPKEkaAV5s+6vA14E319uiiP4kwEc85e3AF8rXV5BhmpjhEuAjnvInFIEd28uA50nau94mRfQuAT4CkLQr8I+2H+xIPhUYqadFEf1TNvyIiGin9OBjqyfpPZLmlK8l6QpJP5O0UtKBdbcvolcJ8BHwF8APytcnAvsD+wIfAi6qqU0RfUuAj4CNtp8oXx8DXGn7EdtfB3assV0RfUmAj4BRSc+TtAPweoo58GOeWVObIvqWJ/Ui4ExgOTALWGJ7FYCk1wD31dmwaLb58+d7/fr1XfOtWLFiqe35Q2jSZjKLJnoi6Srbb++WNlOUyxLsbPvRjrQdKX5Hfl5fy6LJ5s2b52XLlnXNt80226ywPW8ITdpMevDRqxd3nkiaBRxcU1uq8Fzg/ZLGPtcq4BLb/1ljm2IGGG1wJzlj8LFFJJ0haQOwfzmV8Gfl+Y+Bf625eT2R9CpgrBt2ZXkAfLe8FjEhA7a7HnVJD75FJB0EHErx9+5W27dXXYftjwMfl/Rx22dUXX5NLgDebPuOjrQlkq4DPg28op5mRfMZ09wefAJ8S0g6E/gj4Etl0hWSvmj73IrreaHte4Evll8omxnEl8oQPHtccAfA9p2Sdq6jQTFDGDaNJsA3jqRDgTm2r5C0O7CT7fvrblcf/hh4me1fA0j6BHAnUGmAp3j4ZwFFr3c8A6+ruL5hkKTndN5gLROfS4YxYwqm2WPwW2WAl/RXwDzgdyhWD9wW+Bwwk8dbHwJ2AH5dnm8PPDh59t7YXlC+PHrsy2RMOY98JvokcKOkU4Gxf4EcDJxXXouYVJNnIm6VAR74Q+BAyl9m2w8N6p/ikra3/ZtuaRV4DFgl6WsUHYsjgdskXQRg+88rru/bwPghmonSGs/2IkkPAedQzA4ysBo41/b/rbVx0XgJ8M3zuG1LMjw533lQ/p2nB72J0vp1XXmMubni8gGQtAewJ/DMciEulZeeDTxrEHUOg+0vA1+uux0xs9jOEE0DXSPp08Cukt5DsdHDZ6qsYNiB0PZiSdsB+5VJazrWV6nS7wPvAvYC/q4j/WfA/x5AfQMn6Rrbby1fn2f79I5rN9o+qr7WRdOlB98wtv9W0pEUQel3gDNtf63iajoD4QU8FeA3MIBAKOlwYDHFqogC9pb0Ttu3VFmP7cXAYknH2f4/VZZdozkdr48ETu84333IbYkZxMCmBPjmKQN61UG9s/xhB8ILgKNsrwGQtB/F/qKDerr0VkmXAc+3fbSkucDv2r5sQPUN0lS/oc397Y1GaHIPfquaAiZpQ8fTl53HBkk/G1C1e0l6drmRxKWSbpc0iH/ybzsW3AFsf59idtCgXAEsBZ5fnn8f+OAA6xukZ0k6UNLBlENqkg4aO6+7cdFso+U4/FRHXbaqHrztOh5a+RPbF0r6fWA34O3AVcCNFdezQtKlFNM9oZgXv7ziOjqN2L5G0hkAtjdK2jTA+gbpRzx1P+FhNr+38PDwmxMzRs1LEXSzVQX48sGVSdn+6SCqLX/+AcVGEqskaao39Oh9wPuBsemQ/wZcMoB6xvxC0m6UQxiSXkkxVXPGsf3autsQM9PYWjRNtVUFeGAFxZ+JeGpsdSzYGvjtQdQpaWlZ9sJyvv1olRWUKzneZfuFbN77HKQPAUuA35Z0K8XNyLcMqe7KSXomsJ/tuzrS9gE22a78gbFoj02jlf46V2qrCvC29wWQtA3FEMa+ts8uf5GfN6BqTwY+Cqy2/cuyrg9WWYHtTZLWSNrH9n9UWfYUVlPMu/8lxcyg6ynG4WeqjcCXJO1v+xdl2qUUM54S4GMSzV5sbKu6ydrhYuCVFBssQxGg/nGAdf03YGw3lw0Mppf9HIonWb8hacnYMYB6xlwJvBD4a+AfKObfXzXA+gaqfGbgOmBsPvw+wO62B3kfI2Y4G0ancdRlq+rBd3iF7YMk3QFg+9HyIaGZXNcOFBtGjxHFWiqD8hLbczvOb5K0eoD1DcOlwCKKGULvKH9GTClj8M3zRDluPXaDcHcqHhevoa5n2P5WZ0I5rjwot0t6pe3vlHW9gsHO2hk42/eW01n3A04ADqu7TdF8CfDNcxHFP8d/S9LHKG4OfnQm1iXpT4E/o7jZubLj0s7ArVXVM4GDgW9LGhvz3wdYI+luwLb3H2DdSNrD9iCmMF5G0ZO/e/zywRHjZbngBrL9eUkrgNdTDGW82fb3Zmhd/wx8Ffg4sLAjfcOApn2OGfoO8eNcRjH1tGrXABcCZw+g7GgbO7NomqjclejemV6X7cco5p+f2C1vxfX+cJj1TVD/III7tn8J7DKIsqOdMkQTEdFChkZPk0yAj4joQ4O3ZN1q58E/SdKC7rlSVxPqauNnSl0zp57JuFyPZqqjLlt9gKfYQDp1zYy62viZUtfMqWdCTQ7wGaKJiOiRM4tmeEZGRjx79uwtes8+++zDvHnztvgrdsWKFVv6FgDG9oEdhjbW1cbPlLpqq2e97b537MosmiGZPXs2y5cP52HKwaz4GxFD1PdU3zzoFBHRYpkmGRHRUk2eJpkAHxHRI9uM5iZrREQ7ZQw+IqKlMosmIqKlEuAjIlrIdqOHaGpfqkDSDySN1N2OiIheeBr/1SU9+IiIHhnY1OB5kkPtwUvaUdJXJN0l6R5Jx5eXPiDpdkl3S3phR97LJd0m6Q5Jxw6zrRER01HVYmOS5ktaI2mtpIUTXN9H0k1lPFwp6Q3dyhz2EM184CHbL7P9EuD/lenrbR8EfAo4tUz7CPBN24cArwXOl7TjkNsbETGl0XIcfqqjG0mzgIuBo4G5wImS5o7L9lHgGtsHUmwKf0m3cocd4O8GjpR0nqTDyu3mAL5U/lwBzC5fHwUslHQncDOwA8XGzpuRtEDScknLf/KTnwyy7RERm5tG732aPfhDgLW277P9OHA1MH7UwsCzy9e7AA91K3SoY/C2vy/pIOANwLmSvlFe+k35c1NHmwQcZ3tNlzIXAYuAnlaFjIjolalsmuSewAMd5+uAV4zLcxZwo6QPADsCR3QrdNhj8M8Hfmn7c8D5wEFTZF9KMTav8r0HDqGJERFbZJpDNCNjIw3l0csmJScCn7W9F0Un+SpJU8bwYc+ieSnFWPoo8ATwp8C1k+Q9B/h7YGX5Ie4HjhlGIyMipmua8+DX2543xfUHgb07zvcq0zqdTHEfE9v/LmkHYAT48WSFDnuIZilFz7zT7I7ry4HDy9e/At47rLZFRGypCteDXwbMkbQvRWA/AThpXJ7/AF4PfFbSiyjuS0554zHz4CMielXRnqu2N0o6haIDPAu43PYqSWcDy20vAT4MfEbS/6L4bnmXu1SeAB8R0YeqliqwfQNww7i0MzterwZetSVlJsBHRPSowlk0A5EAHxHRh03Z8CMioo3qXUysmwT4iIge2cXRVAnwERF9aPJ68AnwERF9yE3WIVmxYgXlygbRg2H+Rc2fU7RBhQ86DUSrAnxExFDZjGYWTURES6UHHxHRTm7wln0J8BERfWhwBz4BPiKiV8U8+OZG+AT4iIg+JMBHRLSSGd2UWTQREa2TIZqIiBZrcoAf6qbb0yXp23W3ISJiWsZWHJvqqEkje/C2f6/uNkRETEeDO/CN7cH/vPz5PEm3SLpT0j2SDqu7bRERT3Jxk7XbUZdG9uA7nAQstf0xSbOAZ9XdoIiIMdmyrz/LgMslbQtcb/vO8RkkLQAWDLthERHQ7ADfyCGaMbZvAV4NPAh8VtI7JsizyPY82/OG3sCI2OrZ7nrUpdE9eEkvANbZ/oyk7YGDgCtrblZERMGGLDbWs8OB0yQ9AfwceFoPPiKiTk0eomlkgLe9U/lzMbC45uZEREzIwGh68BERLZSlCiIi2isbfkREtFK9s2S6SYCPiOhDAnxERAtlueCIiBbzpgT4iIhWSg8+IqKNal6KoJsE+HiSpKHVNcxfimF+rtj6JMBHRLRQ05cLbvRqkhERjWbwptGux3RImi9pjaS1khZOkuetklZLWiXpn7uVmR58RETPqhmDLzc0uhg4ElgHLJO0xPbqjjxzgDOAV9l+VNJvdSs3PfiIiD5UtOf2IcBa2/fZfhy4Gjh2XJ73ABfbfrSo1z/uVmgCfEREH6a54ceIpOUdx/hd6PYEHug4X1emddoP2E/SrZK+I2l+t7ZliCYiokf2tBcbW1/BrnPPAOZQ7JOxF3CLpJfa/q/J3pAefEREHyrasu9BYO+O873KtE7rgCW2n7B9P/B9ioA/qQT4iIiemdHR0a7HNCwD5kjaV9J2wAnAknF5rqfovSNphGLI5r6pCs0QTURErypabMz2RkmnAEuBWcDltldJOhtYbntJee0oSauBTcBpth+ZqtyhB3hJuwIn2b5k2HVHRFSuog0/bN8A3DAu7cyO1wY+VB7TUscQza7An9VQb0REpYonWSuZJjkQdQT4TwD/XdKdks4vj3sk3S3peAAVnpYeEdE0Fd1kHYg6xuAXAi+xfYCk44D3AS8DRiie3roF+D3ggPHptn9UQ3sjIiZmMzrNpQjqUPcsmkOBL9jeZPs/gW8BL58i/WkkLRh7eGBorY6IKKUHP0C2FwGLACQ1d1m3iGidrCb5dBuAncvX/wYcL2mWpN2BVwO3TZEeEdEcDb/LOvQevO1HyrUU7gG+CqwE7qL4X/WXth+WdB3wu+PTh93WiIipZUenp7F90rik08Zdd5l2GhERDebm3mOd+WPwERG1MdNdiqAWCfARET1q+k3WBPiIiD4kwEdEtJKnux58LRLgIyJ6VdFqkoOSAB8R0Y8E+IiI9jEwmiGaiIgWmv6erLVIgI+I6FmeZI2IaK0E+IiIlkqAj4hoIRvc4A0/EuAjIvrQ4A58AnxERO9ykzUiorUS4CMi2ihLFUREtJPJg04RES1lvDVv+CHpLODntv920HVFRAxVhmgiItqrwfGdbaouUNI7JK2UdJekq8ZdO0DSd8rr10l6Tpn+55JWl+lXl2k7Srpc0m2S7pB0bNVtjYjol0fd9ahLpQFe0ouBjwKvs/0y4C/GZbkSON32/sDdwF+V6QuBA8v095VpHwG+afsQ4LXA+ZJ2nKDOBZKWS1pe5WeJiOhmbE/Wbkddqu7Bvw74ou31ALZ/OnZB0i7Arra/VSYtBl5dvl4JfF7S24CNZdpRwEJJdwI3AzsA+4yv0PYi2/Nsz6v4s0RETM3NDvBNGYP/A4pg/0bgI5JeCgg4zvaaWlsWETEpM9rgWTRV9+C/CfyRpN0AJD137ILtx4BHJR1WJr0d+JakbYC9bd8EnA7sAuwELAU+IEllWQdW3NaIiL41eQy+0h687VWSPkYRuDcBdwA/6MjyTuCfJD0LuA/4n8As4HPlEI6Ai2z/l6RzgL8HVpZfAvcDx1TZ3oiIvhSD8HW3YlKVD9HYXkwxvj7RtTuBV05w6dAJ8v4KeG+ljYuIqFCV8V3SfOBCik7vpbY/MUm+44BrgZfbnnJySeXTJCMitiZV3GSVNAu4GDgamAucKGnuBPl2ppid+N3ptC0BPiKiVzajm0a7HtNwCLDW9n22HweuBiZ69ucc4Dzg19MpNAE+IqIPFU2T3BN4oON8XZn2JEkHUUxI+cp029aUaZIRETPO2INO0zAy7mHMRbYXTbeecqLJ3wHv2pL2JcBHRPRhmgF+fZeHMR8E9u4436tMG7Mz8BLg5nLm+B7AEklvmupGawJ8RETPXNU0mmXAHEn7UgT2E4CTnqyleI5oZOxc0s3AqZlFExExKAaPdj+6FmNvBE6heMDze8A15XNFZ0t6U6/NSw8+alH+M3MohrkWyDA/VzRDVUsV2L4BuGFc2pmT5D18OmUmwEdE9GgLbrLWIgE+IqJX2dEpIqKt6l1MrJsE+IiIfqQHHxHRTiYBPiKidWwzOrqp7mZMKgE+IqIPuckaEdFSCfARES2VAB8R0ULFcsDN3XQ7AT4iog8J8BERLZUhmoiIlkqAHyBJC4AFdbcjIrZGGYMfqHLbq0UAkpr7VRoRreMsNhYR0V5NDvAzZkcnSTdIen7d7YiIeIrx6GjXoy4zpgdv+w11tyEiYjyTMfiIiFZq8hBNAnxERI9ykzUiorWcAB8R0VZZDz4ioqXSg4+IaKNiEL7uVkwqAT4iokcme7JGRLRW1qKJqJGkodX1/tPOH1pdF59/2lDq+fBZ/zCUegAuOOsDQ6urGplFExHRWqM1LkXQTQJ8RESPinusCfARES2UIZqIiPZKgI+IaKdMk4yIaKkM0UREtJDtrEUTEdFWTe7Bz5gt+yIimsh212M6JM2XtEbSWkkLJ7j+IUmrJa2U9A1JL+hWZt8BXtLNZaPuLI9rO64tkHRvedwm6dCOa8dIukPSXWWj39tvWyIihq2KAC9pFnAxcDQwFzhR0txx2e4A5tneH7gW+Jtu5fY0RCNpO2Bb278ok/7Y9vJxeY4B3gscanu9pIOA6yUdAjwCLAIOsb1O0vbA7PJ9z7H9aC/tiogYLkM1DzodAqy1fR+ApKuBY4HVT9Zk39SR/zvA27oVukU9eEkvknQBsAbYr0v204HTbK8vG3c7sBh4P7AzxZfLI+W139heU77veEn3SPqwpN23pH0REcNkw6hHux7AiKTlHceCcUXtCTzQcb6uTJvMycBXu7Wvaw9e0o7AW8sCAa4AzrK9oSPb5yX9qnz9NdunAS8GVowrbjnwTts/lbQE+KGkbwBfBr5ge9T2P0n6CvAu4BZJq4BLgRvd5GeCI2KrNM0x9vW251VRn6S3AfOA13TLO50hmh8BK4F32753kjxPG6Lpxva7Jb0UOAI4FTiSIqhj+wHgHEnnUoxJXU7x5fCm8eWU34Tjvw0jIobAVa1F8yCwd8f5XmXaZiQdAXwEeI3t33QrdDpDNG8pK/qSpDOnc+e2tBo4eFzawcCqsRPbd9v+JEVwP64zYzlWfwlwEXANcMZEldheZHteVd+OERFboqJZNMuAOZL2Le9xngAs6cwg6UDg08CbbP94OoV2DfC2b7R9PHAY8Bjwr5K+Lml2l7f+DXCepN3Kxh1A0UO/RNJOkg7vyHsA8MMy31GSVgLnAjcBc21/0PYqIiIapooAb3sjcAqwFPgecI3tVZLOljQ2cnE+sBPwxXLG4pJJinvStGfR2H4EuBC4sOxddz6+1TkGv972EbaXSNoT+LYkAxuAt9n+kaSdgb+U9GngV8AvKIdnKG68vtH2D6fbtoiIOhTLBVfzoJPtG4AbxqWd2fH6iC0ts6dpkrZv63h9+BT5PgV8aoL0DcAbJnnP+BuzERENZewsVRAR0UpNXqogAT4iog8J8BERrZQdnSIiWil7skZEtFh68BERrWQ8mh58REQrZU/WiIiWavIYvJo8frSlJP2EcsmDLTACrB9Ac1LXzK0ndc2sunqt5wW2+1qSfLvtnuk99pjdNd8DD9y7oo71slrVg+/lD0vS8mH9j09dM6Oe1DWz6hrmZ3q6TJOMiGit0dxkjYhopyaPwSfAF3vDpq6ZUVcbP1Pqmjn1PF3xpFNt1XfTqpusERHDtO2223tkZKqtUwsPP3x/brJGRMw0Te4kJ8BHRPQhY/AREa3kzKKJiGijKrfsG4QE+IiIPiTAR0S0kiFj8BER7ZTVJCMiWipDNBERLWSb0dFNdTdjUgnwERF9SA8+IqKlEuAjIloqAT4ioq0S4CMi2sc2o85N1oiIVsoQTURESyXAR0S0UjbdjohorawHHxHRQk1fLnibuhsQETFzGXu06zEdkuZLWiNpraSFE1zfXtK/lNe/K2l2tzIT4CMi+lBFgJc0C7gYOBqYC5woae64bCcDj9r+H8AngfO6lZsAHxHRB9tdj2k4BFhr+z7bjwNXA8eOy3MssLh8fS3wekmaqtAE+IiIPlQU4PcEHug4X1emTZjH9kbgMWC3qQrNTdaIiN4tBUamkW8HScs7zhfZXjSgNj0pAT4ioke251dU1IPA3h3ne5VpE+VZJ+kZwC7AI1MVmiGaiIj6LQPmSNpX0nbACcCScXmWAO8sX78F+Ka7jP+kBx8RUTPbGyWdQjHkMwu43PYqSWcDy20vAS4DrpK0FvgpxZfAlNTkSfoREdG7DNFERLRUAnxEREslwEdEtFQCfERESyXAR0S0VAJ8RERLJcBHRLRUAnxEREv9f6YWIy0AONUJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input = je ne crains pas de mourir .\n",
            "output = i m not scared to die . <EOS>\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input = c est un jeune directeur plein de talent .\n",
            "output = he s a talented young lady . <EOS>\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1a3GYF4NzeG"
      },
      "source": [
        "# 8. Conclusion <a class=\"anchor\" id=\"17\"></a>\n",
        "\n",
        "Attention Mechanism has been proposed in RNN to prevent deterioration in translation performance due to bottlenecks when sentence length is extended. Recently, self-attention concepts that parallelize them have emerged, and even models that use self-attention to perform better without RNN (Transformer, BERT, etc.) have been pouring out. In order to understand and learn the underlying skills of the latest models, I think it is essential to study Attention Mechanism well.\n",
        "\n",
        "[Back to Table of Contents](#0.1)\n",
        "\n",
        "[Back to fra-eng Table of Contents](#0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4AOofmtNzeH"
      },
      "source": [
        "# 9. References <a class=\"anchor\" id=\"18\"></a>\n",
        "\n",
        "* NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE : https://arxiv.org/pdf/1409.0473.pdf\n",
        "\n",
        "* Attention Mechanism Cleanup Notes : https://wikidocs.net/22893\n",
        "\n",
        "* Attention Mechanism blog1 : http://blog.naver.com/PostView.nhn?blogId=ckdgus1433&logNo=221608376139\n",
        "\n",
        "* Attention Mechanism blog2 : https://sy-programmingstudy.tistory.com/14\n",
        "\n",
        "* Teacher Forcing : https://m.blog.naver.com/PostView.nhn?blogId=sooftware&logNo=221790750668&categoryNo=16&proxyReferer=https:%2F%2Fwww.google.com%2F\n",
        "\n",
        "* Attention Mechanism YouTube : https://www.youtube.com/watch?v=WsQLdu2JMgI&t=364s\n",
        "\n",
        "* Attention Mechanism using Tensorflow YouTube : https://www.youtube.com/watch?v=aUsGQaqYYBk&t=3202s\n",
        "\n",
        "* NLP FROM SCRATCH: TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION : https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#nlp-from-scratch-translation-with-a-sequence-to-sequence-network-and-attention\n",
        "\n",
        "* fra-eng data : https://www.manythings.org/anki/\n",
        "\n",
        "For more details: https://www.kaggle.com/jeongwonkim10516/attention-mechanism-for-nlp-beginners/log\n",
        "*italicized text*"
      ]
    }
  ]
}