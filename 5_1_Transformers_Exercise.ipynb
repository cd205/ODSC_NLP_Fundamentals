{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5.1 Transformers Exercise",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azPu1ZgldM2J",
        "outputId": "b1ef995b-f317-4700-a63f-25b35015859d"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 27.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 37.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 44.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljQtSFionBk4",
        "outputId": "ca15b54e-b623-4667-f829-f12860db1d02"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "from tqdm import tqdm, trange\n",
        "import re\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "data_path = '/content/drive/MyDrive/Colab Notebooks/Online course/data/toxic-comment-classification-challenge/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please download the data here: https://drive.google.com/drive/folders/1GYizuTQVGLvBpFi8fmFbAV__PW4e48Tw?usp=sharing"
      ],
      "metadata": {
        "id": "rulDdKn59ToJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkMEbYgQm863"
      },
      "source": [
        "test_file = os.path.join(data_path, 'test.csv.zip')\n",
        "labels_file = os.path.join(data_path, 'test_labels.csv.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BFXVAEk545N"
      },
      "source": [
        "X_train = pd.read_csv(test_file)\n",
        "y_train = pd.read_csv(labels_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ALJe8CHInL2O",
        "outputId": "b131b963-7531-474d-a096-3da091c81396"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  toxic  severe_toxic  ...  threat  insult  identity_hate\n",
              "0  00001cee341fdb12     -1            -1  ...      -1      -1             -1\n",
              "1  0000247867823ef7     -1            -1  ...      -1      -1             -1\n",
              "2  00013b17ad220c46     -1            -1  ...      -1      -1             -1\n",
              "3  00017563c3f7919a     -1            -1  ...      -1      -1             -1\n",
              "4  00017695ad8997eb     -1            -1  ...      -1      -1             -1\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "jFkgAInGIQoB",
        "outputId": "ba93cfb9-3748-499f-b414-3b433a751a90"
      },
      "source": [
        "y_train.set_index('id').value_counts(normalize=True).plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdab87a8710>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "v_nCXb3PHv_u",
        "outputId": "9bdf8c1f-30a2-4530-f83c-ab56d561c67d"
      },
      "source": [
        "X_train[y_train['toxic'] == 1].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>00091c35fa9d0465</td>\n",
              "      <td>== Arabs are committing genocide in Iraq, but ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0013fed3aeae76b7</td>\n",
              "      <td>DJ Robinson is gay as hell! he sucks his dick ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>0017d4d47894af05</td>\n",
              "      <td>:Fuck off, you anti-semitic cunt.  |</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>001d739c97bc2ae4</td>\n",
              "      <td>How dare you vandalize that page about the HMS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>001eff4007dbb65b</td>\n",
              "      <td>::No, he is an arrogant, self serving, immatur...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id                                       comment_text\n",
              "21  00091c35fa9d0465  == Arabs are committing genocide in Iraq, but ...\n",
              "48  0013fed3aeae76b7  DJ Robinson is gay as hell! he sucks his dick ...\n",
              "59  0017d4d47894af05               :Fuck off, you anti-semitic cunt.  |\n",
              "76  001d739c97bc2ae4  How dare you vandalize that page about the HMS...\n",
              "81  001eff4007dbb65b  ::No, he is an arrogant, self serving, immatur..."
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "IbM4zle0VG0D",
        "outputId": "8cb23b8d-ad5d-431d-a9bf-928c99dfb4e1"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00013b17ad220c46</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00017563c3f7919a</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00017695ad8997eb</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  toxic  severe_toxic  ...  threat  insult  identity_hate\n",
              "0  00001cee341fdb12     -1            -1  ...      -1      -1             -1\n",
              "1  0000247867823ef7     -1            -1  ...      -1      -1             -1\n",
              "2  00013b17ad220c46     -1            -1  ...      -1      -1             -1\n",
              "3  00017563c3f7919a     -1            -1  ...      -1      -1             -1\n",
              "4  00017695ad8997eb     -1            -1  ...      -1      -1             -1\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "71iXoWG3VXkr",
        "outputId": "0d946f98-a105-4d60-c64e-b70f7dc090a7"
      },
      "source": [
        "y_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>153164.000000</td>\n",
              "      <td>153164.000000</td>\n",
              "      <td>153164.000000</td>\n",
              "      <td>153164.000000</td>\n",
              "      <td>153164.000000</td>\n",
              "      <td>153164.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.542530</td>\n",
              "      <td>-0.579895</td>\n",
              "      <td>-0.558193</td>\n",
              "      <td>-0.580913</td>\n",
              "      <td>-0.559916</td>\n",
              "      <td>-0.577642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.572465</td>\n",
              "      <td>0.498408</td>\n",
              "      <td>0.542966</td>\n",
              "      <td>0.496195</td>\n",
              "      <td>0.539594</td>\n",
              "      <td>0.503260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               toxic   severe_toxic  ...         insult  identity_hate\n",
              "count  153164.000000  153164.000000  ...  153164.000000  153164.000000\n",
              "mean       -0.542530      -0.579895  ...      -0.559916      -0.577642\n",
              "std         0.572465       0.498408  ...       0.539594       0.503260\n",
              "min        -1.000000      -1.000000  ...      -1.000000      -1.000000\n",
              "25%        -1.000000      -1.000000  ...      -1.000000      -1.000000\n",
              "50%        -1.000000      -1.000000  ...      -1.000000      -1.000000\n",
              "75%         0.000000       0.000000  ...       0.000000       0.000000\n",
              "max         1.000000       1.000000  ...       1.000000       1.000000\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFjAU5EdVddd",
        "outputId": "d2d41dd9-b821-4c3e-89fb-3dcb604017c1"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4-y9i1CZORQ"
      },
      "source": [
        "import string\n",
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove square brackets, links, punctuation\n",
        "    and numbers.'''\n",
        "    text = text.lower()\n",
        "    \n",
        "    #all characters in square brackets \n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "\n",
        "    #web address\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    \n",
        "    #punctionation\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    \n",
        "    #new line\n",
        "    text = re.sub('\\n', '', text)\n",
        "    \n",
        "    #non characters\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DprJO854dYH-"
      },
      "source": [
        "X_train['comment_text'] = X_train['comment_text'].apply(clean_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UggGy6TNjo5s",
        "outputId": "1624d53c-a181-4106-8e1b-9c496d48ec7f"
      },
      "source": [
        "X_train['comment_text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         yo bitch ja rule is more succesful then youll ...\n",
              "1                 from rfc   the title is fine as it is imo\n",
              "2                   sources    zawe ashton on lapland —    \n",
              "3         if you have a look back at the source the info...\n",
              "4                   i dont anonymously edit articles at all\n",
              "                                ...                        \n",
              "153159      i totally agree this stuff is nothing but to...\n",
              "153160     throw from out field to home plate   does it ...\n",
              "153161       okinotorishima categories   i see your chan...\n",
              "153162       one of the founding nations of the eu  germ...\n",
              "153163      stop already your bullshit is not welcome he...\n",
              "Name: comment_text, Length: 153164, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ-PeyJ3j0QL",
        "outputId": "09a4657a-c54f-4287-fafc-a840f7bac6a3"
      },
      "source": [
        "senten_len = []\n",
        "train_batch = 32\n",
        "valid_batch = 32\n",
        "\n",
        "for sentence in tqdm(X_train['comment_text']):\n",
        "    token_words = tokenizer.encode_plus(sentence)['input_ids']\n",
        "    senten_len.append(len(token_words))\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(X_train, batch_size = train_batch, pin_memory = True, num_workers = 4, shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 153164/153164 [00:42<00:00, 3603.07it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFSFGoEAeEzW"
      },
      "source": [
        "# Exercize\n",
        "\n",
        "use BERT to get the vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6f7ldZXfRiN"
      },
      "source": [
        "# Retrainig part of the model\n",
        "\n",
        "\n",
        "amp stands for automatic mixed precision.\n",
        "To learn more about the autocast read this link:\n",
        "https://pytorch.org/docs/stable/amp.html\n",
        "in short: Instances of autocast serve as context managers or decorators that allow regions of your script to run in mixed precision, where some operations use the torch.float32 (float) datatype and other operations use torch.float16 (half). autocast should wrap only the forward pass(es) of your network, including the loss computation(s). Backward passes under autocast are not recommended.\n",
        "\n",
        "with statement in Python is used in exception handling to make the code cleaner and much more readable. It simplifies the management of common resources like file streams. Here is a link to learn more about it.\n",
        "https://www.geeksforgeeks.org/with-statement-in-python/\n",
        "\n",
        "Non-Blocking allows you to overlap compute and memory transfer to the GPU. Pinned Memory allows the non-blocking calls to actually be non-blocking.\n",
        "\n",
        "Why using var.detach().cpu().numpy() and not var.numpy() only?\n",
        "because we get an error. The main reason behind this choice presumably is to avoid confusing new comers. People not very familiar with requires_grad and cpu/gpu Tensors might go back and forth with numpy. For example doing pytorch -> numpy -> pytorch and backward on the last Tensor. This will backward without issue but not all the way to the first part of the code and won’t raise any error. So the choice has been made to force the user to detach() to make sure they want to do it and it’s not a typo/other library that does this tranformation and breaks the computational graph.\n",
        "\n",
        "optimizer.step(): it performs a parameter update based on the current gradient (stored in .grad attribute of a parameter) and the update rule. As an example, the update rule for SGD is defined here:\n",
        "https://github.com/pytorch/pytorch/blob/cd9b27231b51633e76e28b6a34002ab83b0660fc/torch/optim/sgd.py#L63\n",
        "\n",
        "loss.backward() Calling .backward() mutiple times accumulates the gradient (by addition) for each parameter. This is why you should call optimizer.zero_grad() after each .step() call. Note that following the first .backward call, a second call is only possible after you have performed another forward pass.\n",
        "\n",
        "Gradient Scaling\n",
        "If the forward pass for a particular op has float16 inputs, the backward pass for that op will produce float16 gradients. Gradient values with small magnitudes may not be representable in float16. These values will flush to zero (“underflow”), so the update for the corresponding parameters will be lost.\n",
        "\n",
        "To prevent underflow, “gradient scaling” multiplies the network’s loss(es) by a scale factor and invokes a backward pass on the scaled loss(es). Gradients flowing backward through the network are then scaled by the same factor. In other words, gradient values have a larger magnitude, so they don’t flush to zero.\n",
        "\n",
        "Each parameter’s gradient (.grad attribute) should be unscaled before the optimizer updates the parameters, so the scale factor does not interfere with the learning rate.\n",
        "\n",
        "step() carries out the following two operations:\n",
        "\n",
        "Internally invokes unscale(optimizer) (unless unscale() was explicitly called for optimizer earlier in the iteration). As part of the unscale_(), gradients are checked for infs/NaNs.\n",
        "If no inf/NaN gradients are found, invokes optimizer.step() using the unscaled gradients. Otherwise, optimizer.step() is skipped to avoid corrupting the params."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udn-DqrNaVlf"
      },
      "source": [
        "def training(train_dataloader, model, optimizer, scheduler):\n",
        "    model.train()\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    correct_predictions = 0\n",
        "    \n",
        "    for a in train_dataloader:\n",
        "        losses = []\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        with torch.cuda.amp.autocast():\n",
        "            \n",
        "            ids = a['ids'].to(device, non_blocking = True)\n",
        "            mask = a['mask'].to(device, non_blocking = True) \n",
        "\n",
        "            output = model(ids, mask) #This gives model as output, however we want the values at the output\n",
        "            output = output['logits'].squeeze(-1).to(torch.float32)\n",
        "\n",
        "            output_probs = torch.sigmoid(output)\n",
        "            preds = torch.where(output_probs > 0.5, 1, 0)\n",
        "            \n",
        "            toxic_label = a['toxic_label'].to(device, non_blocking = True) \n",
        "            loss = loss_fn(output, toxic_label)            \n",
        "            \n",
        "            losses.append(loss.item())\n",
        "            #allpreds.append(output.detach().cpu().numpy())\n",
        "            #alltargets.append(toxic.detach().squeeze(-1).cpu().numpy())\n",
        "            correct_predictions += torch.sum(preds == toxic_label)\n",
        "        \n",
        "        scaler.scale(loss).backward() #Multiplies (‘scales’) a tensor or list of tensors by the scale factor.\n",
        "                                      #Returns scaled outputs. If this instance of GradScaler is not enabled, outputs are returned unmodified.\n",
        "        scaler.step(optimizer) #Returns the return value of optimizer.step(*args, **kwargs).\n",
        "        scaler.update() #Updates the scale factor.If any optimizer steps were skipped the scale is multiplied by backoff_factor to reduce it. \n",
        "                        #If growth_interval unskipped iterations occurred consecutively, the scale is multiplied by growth_factor to increase it\n",
        "        scheduler.step() # Update learning rate schedule\n",
        "    \n",
        "    losses = np.mean(losses)\n",
        "    corr_preds = correct_predictions.detach().cpu().numpy()\n",
        "    accuracy = corr_preds/(len(k_train)*6)\n",
        "    \n",
        "    return losses, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_8MVftnqQ1B"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"ticks\", context=\"talk\")\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "import tokenizers\n",
        "from sklearn.metrics import mean_squared_error, roc_auc_score, roc_curve, auc\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "\n",
        "SEED = 11\n",
        "def random_seed(SEED):\n",
        "    random.seed(SEED)\n",
        "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "random_seed(SEED)\n",
        "\n",
        "max_len = 200\n",
        "\n",
        "class BertDataSet(Dataset):\n",
        "    \n",
        "    def __init__(self, sentences, toxic_labels):\n",
        "        self.sentences = sentences\n",
        "        #target is a matrix with shape [#1 x #6(toxic, obscene, etc)]\n",
        "        self.targets = toxic_labels.to_numpy()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "    \n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        bert_senten = tokenizer.encode_plus(sentence, \n",
        "                                            add_special_tokens = True, # [CLS],[SEP]\n",
        "                                            max_length = max_len,\n",
        "                                            pad_to_max_length = True,\n",
        "                                            truncation = True,\n",
        "                                            return_attention_mask = True\n",
        "                                             )\n",
        "        ids = torch.tensor(bert_senten['input_ids'], dtype = torch.long)\n",
        "        mask = torch.tensor(bert_senten['attention_mask'], dtype = torch.long)\n",
        "        toxic_label = torch.tensor(self.targets[idx], dtype = torch.float)\n",
        "        \n",
        "        \n",
        "        return {\n",
        "            'ids' : ids,\n",
        "            'mask' : mask,\n",
        "            'toxic_label':toxic_label\n",
        "        }\n",
        "\n",
        "epochs = 5\n",
        "train_batch = 32\n",
        "valid_batch = 32\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "loss_fn.to(device)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "def training(train_dataloader, model, optimizer, scheduler):\n",
        "    model.train()\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    correct_predictions = 0\n",
        "    \n",
        "    for a in train_dataloader:\n",
        "        losses = []\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #allpreds = []\n",
        "        #alltargets = []\n",
        "        \n",
        "        with torch.cuda.amp.autocast():\n",
        "            \n",
        "            ids = a['ids'].to(device, non_blocking = True)\n",
        "            mask = a['mask'].to(device, non_blocking = True) \n",
        "\n",
        "            output = model(ids, mask) #This gives model as output, however we want the values at the output\n",
        "            output = output['logits'].squeeze(-1).to(torch.float32)\n",
        "\n",
        "            output_probs = torch.sigmoid(output)\n",
        "            preds = torch.where(output_probs > 0.5, 1, 0)\n",
        "            \n",
        "            toxic_label = a['toxic_label'].to(device, non_blocking = True) \n",
        "            loss = loss_fn(output, toxic_label)            \n",
        "            \n",
        "            losses.append(loss.item())\n",
        "            #allpreds.append(output.detach().cpu().numpy())\n",
        "            #alltargets.append(toxic.detach().squeeze(-1).cpu().numpy())\n",
        "            correct_predictions += torch.sum(preds == toxic_label)\n",
        "        \n",
        "        scaler.scale(loss).backward() #Multiplies (‘scales’) a tensor or list of tensors by the scale factor.\n",
        "                                      #Returns scaled outputs. If this instance of GradScaler is not enabled, outputs are returned unmodified.\n",
        "        scaler.step(optimizer) #Returns the return value of optimizer.step(*args, **kwargs).\n",
        "        scaler.update() #Updates the scale factor.If any optimizer steps were skipped the scale is multiplied by backoff_factor to reduce it. \n",
        "                        #If growth_interval unskipped iterations occurred consecutively, the scale is multiplied by growth_factor to increase it\n",
        "        scheduler.step() # Update learning rate schedule\n",
        "    \n",
        "    losses = np.mean(losses)\n",
        "    corr_preds = correct_predictions.detach().cpu().numpy()\n",
        "    accuracy = corr_preds/(len(k_train)*6)\n",
        "    \n",
        "    return losses, accuracy\n",
        "\n",
        "def validating(valid_dataloader, model):\n",
        "    \n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    all_output_probs = []\n",
        "    \n",
        "    for a in valid_dataloader:\n",
        "        losses = []\n",
        "        ids = a['ids'].to(device, non_blocking = True)\n",
        "        mask = a['mask'].to(device, non_blocking = True)\n",
        "        output = model(ids, mask)\n",
        "        output = output['logits'].squeeze(-1).to(torch.float32)\n",
        "        output_probs = torch.sigmoid(output)\n",
        "        preds = torch.where(output_probs > 0.5, 1, 0)\n",
        "            \n",
        "        toxic_label = a['toxic_label'].to(device, non_blocking = True)\n",
        "        loss = loss_fn(output, toxic_label)\n",
        "        losses.append(loss.item())\n",
        "        all_output_probs.extend(output_probs.detach().cpu().numpy())\n",
        "        \n",
        "        correct_predictions += torch.sum(preds == toxic_label)\n",
        "        corr_preds = correct_predictions.detach().cpu().numpy()\n",
        "    \n",
        "    losses = np.mean(losses)\n",
        "    corr_preds = correct_predictions.detach().cpu().numpy()\n",
        "    accuracy = corr_preds/(len(p_valid)*6)\n",
        "    \n",
        "    return losses, accuracy, all_output_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FVu6-nVnvQg"
      },
      "source": [
        "# Validating function\n",
        "validating function is quite similar to training function. The difference is that there is no back-propagation and optemization for parameters in it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4kjgO4knyoG"
      },
      "source": [
        "def validating(valid_dataloader, model):\n",
        "    \n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    all_output_probs = []\n",
        "    \n",
        "    for a in valid_dataloader:\n",
        "        losses = []\n",
        "        ids = a['ids'].to(device, non_blocking = True)\n",
        "        mask = a['mask'].to(device, non_blocking = True)\n",
        "        output = model(ids, mask)\n",
        "        output = output['logits'].squeeze(-1).to(torch.float32)\n",
        "        output_probs = torch.sigmoid(output)\n",
        "        preds = torch.where(output_probs > 0.5, 1, 0)\n",
        "            \n",
        "        toxic_label = a['toxic_label'].to(device, non_blocking = True)\n",
        "        loss = loss_fn(output, toxic_label)\n",
        "        losses.append(loss.item())\n",
        "        all_output_probs.extend(output_probs.detach().cpu().numpy())\n",
        "        \n",
        "        correct_predictions += torch.sum(preds == toxic_label)\n",
        "        corr_preds = correct_predictions.detach().cpu().numpy()\n",
        "    \n",
        "    losses = np.mean(losses)\n",
        "    corr_preds = correct_predictions.detach().cpu().numpy()\n",
        "    accuracy = corr_preds/(len(p_valid)*6)\n",
        "    \n",
        "    return losses, accuracy, all_output_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcUyuGR5pqRb"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3nXGo2FtOck"
      },
      "source": [
        "kfold = 3\n",
        "X_train['kfold'] = X_train.index % kfold\n",
        "p_valid = X_train[X_train[\"kfold\"] == 0].reset_index(drop = True)\n",
        "k_train = X_train[X_train[\"kfold\"] != 0].reset_index(drop = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "id": "no9sAh-LplZr",
        "outputId": "2aa736a7-6be8-44c9-8382-227a53b1f651"
      },
      "source": [
        "epochs = 100\n",
        "best_score = 1000\n",
        "train_accs = []\n",
        "valid_accs = []\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "LR = 2e-5\n",
        "optimizer = AdamW(model.parameters(), LR,betas = (0.9, 0.999), weight_decay = 1e-2) # AdamW optimizer\n",
        "train_steps = int(len(k_train)/train_batch * epochs)\n",
        "num_steps = int(train_steps * 0.1)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)\n",
        "\n",
        "for eboch in tqdm(range(epochs)):\n",
        "    \n",
        "    train_loss, train_acc = training(train_dataloader, model, optimizer, scheduler)\n",
        "    valid_loss, valid_acc, valid_probs = validating(valid_dataloader, model)\n",
        "    \n",
        "    print('train losses: %.4f' % train_loss, 'train accuracy: %.3f' % train_acc)\n",
        "    print('valid losses: %.4f' % valid_loss, 'valid accuracy: %.3f' % valid_acc)\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    valid_accs.append(valid_acc)\n",
        "    \n",
        "    \n",
        "    if valid_loss < best_score:\n",
        "        best_score = valid_loss\n",
        "        print('Found a good model!')\n",
        "        state = {\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer_dict': optimizer.state_dict(),\n",
        "            'best_score': best_score\n",
        "        }\n",
        "        torch.save(state, 'best_model.pth')\n",
        "    else:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-fded9ed9ae68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meboch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-0900c863568a>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(train_dataloader, model, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\", line 2898, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1675, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1683, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 85840\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\", line 2906, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\", line 2900, in get_loc\n    raise KeyError(key) from err\nKeyError: 85840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muW3S-tVp9UF"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meGdfb4zpvZV"
      },
      "source": [
        "x = np.arange(epochs)\n",
        "fig, ax = plt.subplots(1, 2, figsize = (15,4))\n",
        "ax[0].plot(x, train_losses)\n",
        "ax[0].plot(x, valid_losses)\n",
        "ax[0].set_ylabel('Losses', weight = 'bold')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].grid(alpha = 0.3)\n",
        "ax[0].legend(labels = ['train losses', 'valid losses'])\n",
        "\n",
        "ax[1].plot(x, train_accs)\n",
        "ax[1].plot(x, valid_accs)\n",
        "ax[1].set_ylabel('Accuracy', weight = 'bold')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].legend(labels = ['train acc', 'valid acc'])\n",
        "\n",
        "ax[1].grid(alpha = 0.3)\n",
        "fig.suptitle('Fold = 0', weight = 'bold') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HPThLNfvT6Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}